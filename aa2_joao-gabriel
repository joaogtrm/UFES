---
title: "aa2_joao_gabriel"
output:
  pdf_document: default
  html_document: default
editor_options:
  markdown:
    wrap: 72
---

## Questão 1)

A estatística "t" é utilizada para avaliar a proporção de ocorrências do
evento "1" na amostra, sendo representada por p̂ = n₁/n, enquanto a
proporção esperada (sob a hipótese nula H₀) é representada por "p".
Dessa forma, o cálculo de "t" pode ser feito da seguinte maneira: $$
t = \frac{\frac{n_1}{n}-p}{\sqrt{\frac{p(1-p)}{n}}}
$$ A estatística "q" está relacionada à frequência de "0's" e "1's".
Consideramos que essas frequências seguem uma distribuição Bernoulli, em
que o valor esperado para a frequência de "1's" é np, e para a
frequência de "0's" é n(1 - p). Dessa forma, o cálculo de "q" pode ser
realizado da seguinte maneira, considerando n₂ = n - n₁ (frequência de
"0's"): $$
q = \frac{{(n_2 - n(1 - p))^2}}{{n(1 - p)}} + \frac{{(n_1 - np)^2}}{{np}}
$$ $$
q = \frac{{n_2^2 - 2n_2(n(1 - p)) + n^2(1 - p)^2}}{{n(1 - p)}}
$$ $$
q = \frac{{n_2^2 + \frac{{n_1^2}}{{n}} - 2n_1p}}{{np(1 - p)}} + \frac{{np^2 + n - 2n_1p}}{{np(1 - p)}}
$$ $$
q = \frac{{np^2 + \frac{{n_1^2}}{{n}} - 2n_1p}}{{p(1 - p)}}
$$ Para demonstrar que q = t², calculamos t²: $$
t^2 = \frac{n}{p(1-p)} \left(\frac{n_1}{n} - p\right)^2 = \frac{n \left(\frac{n_1^2}{n^2} - 2p \frac{n_1}{n} + p^2\right)}{p(1-p)} = \frac{\frac{n_1^2}{n} - 2pn_1 + p^2n}{p(1-p)}
$$ Temos, então, que q = t²

## Questão 2)

Ao substituir as frequências por proporções em q e considerando q̂₁ = 1 -
p̂₁, q̂₂ = 1 - p̂₂, q₁ = 1 - p₁ e q₂ = 1 - p₂, sob a hipótese nula H₀ : p₁
= p₂ = p, e consequentemente, H₀ : q₁ = q₂ = q:

$$
\begin{gathered}
n\left[\frac{\left(\hat{p_1}-p\right)^2}{p}+\frac{\left(\hat{q_1}-q\right)^2}{q}\right]+m\left[\frac{\left(\hat{p_2}-p\right)^2}{p}+\operatorname{frac}\left(\hat{q_2}-q q\right)^2\right]= \\
\frac{n\left(\hat{p_1}-p\right)^2(1-p)+n\left(1-\hat{p_1}-1+p\right)^2 p+m\left(\hat{p_2}-p\right)^2(1-p)+n\left(1-\hat{p_2}-1+p\right)^2 p}{p}= \\
\frac{n\left(\hat{p_1}-p\right)^2(1-p)+n\left(p-\hat{p_1}\right)^2 p+m\left(\hat{p_2}-p\right)^2(1-p)+n\left(p-\hat{p_2}\right)^2 p}{p q}= \\
\frac{n\left(\hat{p_1}-p\right)^2+m\left(\hat{p_2}-p\right)^2}{p q}
\end{gathered}
$$

Substituindo $p=\frac{n p_1+m p_2}{n+m}$ e dividindo o numerador e
denominador por $(n^2 m+m^2 n)$: $$
q=\frac{\left(\hat{p_1}-\hat{p_2}\right)^2}{p q\left(\frac{1}{n}+\frac{1}{m}\right)}=z^2
$$

## Questão 3)

### 1-

$$
\begin{gathered}
E(y_i) = E(\mu + \epsilon_i) = E(\mu) + E(\epsilon_i) = \mu + 0 = \mu \\
\operatorname{Var}(y_i) = \operatorname{Var}(\mu + \epsilon_i) = \operatorname{Var}(\mu) + \operatorname{Var}(\epsilon_i) = 0 + \sigma^2 = \sigma^2
\end{gathered}
$$ $$
\begin{array}{r}
E(y_i y_j) = E[(\mu + \epsilon_i)(\mu + \epsilon_j)] = E(\mu^2 + \mu \epsilon_j + \epsilon_i \mu + \epsilon_i \epsilon_j) = E(\mu^2) + E(\mu \epsilon_j) + E(\epsilon_i \mu) + E(\epsilon_i \epsilon_j) = \\
\mu^2 + \mu E(\epsilon_j) + \mu E(\epsilon_i) + 0 = \mu^2
\end{array}
$$

### 2-

$$
S Q E=\sum_{i=1}^n\left(\overline{y_i}-\mu\right)^2
$$ Para encontrar o mínimo, precisamos encontrar a primeira derivada e
igualá-la a zero. Portanto: $$
\begin{aligned}
\frac{d(S Q E)}{d \mu}=\sum_{i=1}^n-2\left(y_i-\mu\right) \rightarrow \sum_{i=1}^n\left(y_i-\mu\right)=0 \rightarrow \sum_{i=1}^n y_i-\sum_{i=1}^n \mu=0 \rightarrow \sum_{i=1} n y_i-n \mu=0 \\
\qquad \frac{\sum_{i=1}^n y_i}{n}=\mu \rightarrow \mu=\bar{y}
\end{aligned}
$$

### 3-

O estimador possui boas propriedades, como ser não-viesado, ou seja, seu
valor esperado é igual ao parâmetro. Além disso, podemos destacar que
quanto maior o número de observações $n$, mais próximo ele estará de
$\mu$ e possui a menor variância entre os estimadores não-viesados.

### 4-

$$
  \begin{gathered}
S Q R=\sum_{i=1}^n\left(y_i-\bar{y}\right)^2=\sum_{i=1}^n y_i^2-\bar{y}^2 \\
E(S Q R)=\sum_{i=1}^n E\left(y_i^2\right)-E\left(\bar{y}^2\right)=\sum_{i=1}^n \sigma^2+\mu^2-\frac{\sigma^2}{n}-\mu^2=\sum_{i=1}^n \sigma^2-\frac{\sigma^2}{n}=(n-1) \sigma^2 \\
E\left(\frac{S Q R}{n-1}\right)=0 \rightarrow \text { Estimador não viesado }
\end{gathered}
$$

### 5-

Distribuição da média amostral:
$\bar{y} \sim N\left(\mu, \frac{\sigma^2}{n}\right)$

Distribuição amostral de $T: T \sim T_{(n-1)}$

Distribuição amostral de $Q: Q \sim \chi_{(n-1)}^2$

Distribuição amostral de
$\hat{\sigma}^2: \hat{\sigma}^2 \sim \chi_{n-1}^2$

### 6-

$I C(\mu, \gamma)\left[\hat{y}_i+t_\gamma(n-2) S_e \sqrt{\frac{1}{n}+\frac{\left(x_i-\bar{x}\right)^2}{\sum\left(x_i-\bar{x}\right)^2}} ; \hat{y}_i-t_\gamma(n-2) S_e \sqrt{\frac{1}{n}+\frac{\left(x_i-\bar{x}\right)^2}{\sum\left(x_i-\bar{x}\right)^2}}\right]$

### 7-

$$
  I C\left[\sigma^2, \gamma\right]=\left[\frac{(n-1) s^2}{\chi_{(\gamma, n-1)}^2} ; \frac{(n-1) s^2}{\chi_{(\alpha, n-1)}^2}\right]
$$

### 8-

Primeiramente, calculamos a estatística
$T=\frac{\sqrt{n}(\overline{(} y)-\mu_0}{s}$, que apresenta uma
distribuição $t$ - de Student de $n-1$ graus de liberdade. Em seguida,
fixamos um nível de significância $\alpha$ e usamos a tabela da
distribuição $t$ - de Student para achar o valor $t_c$ tal que
$P\left(T<t_c\right)=1-\alpha$. Assim, a região crítica será
$\left[-t_c, t_c\right]$, ou seja, se $T$ estiver nesse intervalo,
rejeitamos $H_0$.

### 9-

Primeiramente, calculamos a estatística
$Q=\frac{(n-1) s^2}{\sigma_0^2}$, que apresenta uma distribuição
qui-quadrado de $n-1$ graus de liberdade. Em seguida, fixamos um nível
de significância $\alpha$ e usamos a tabela da distribuição qui-quadrado
para achar os valores $q_{c 1}$ e $q_{c 2}$ tal que
$P\left(Q \in R C \mid H_0\right)=\alpha$, sendo que a região crítica é
dada por $\left(0, q_{c 1}\right] \cup\left[q_{c 2}, \infty\right)$, ou
seja, se $Q$ estiver nesse intervalo, rejeitamos $H_0$.

### 10-

As hipótese para os erros são: normalidade, média zero, variância constante e independência. Para testar a normalidade podemos usar o teste de Shapiro-Wilk ou gerar um gráfico QQ (quantil-quantil) para a distribuição normal, em que o eixo $\mathrm{X}$ apresenta os quantis teóricos da distribuição normal e o eixo $\mathrm{Y}$ os quantis do resíduo, assumimos que os resíduos seguem a distribuição normal se os pontos estiverem em torno da reta. Para a variância constante podemos usar um teste de homocedasticidade, como o teste Barlett, que testa a igualdade das
variâncias entre os níveis. Essa igualdade também pode ser visualizada
elaborando boxplots para cada nível e comparando a dispersão dos
resíduos. Outra ferramenta útil é um gráfico que representa os resíduos
em função dos valores ajustados, em que, para termos evidências de
variância constante, média zero e independência, os pontos do gráfico
devem distribuir-se de forma aleatória em torno da reta que corresponde
ao resíduo zero.

## Questão 4)

Primeiro, vamos testar as hipóteses:

$$
\begin{align*}
H_0 &: \mu = 30 \\
H_1 &: \mu \neq 30 \\
\end{align*}
$$

Para isso, vamos utilizar um teste-t e analisar o seu valor de p.

```{r}
#Lista com os dados
dados <- c(04.24, 09.94, 11.31, 11.84, 13.89, 19.97, 21.18,
22.15, 22.44, 24.69, 25.20, 25.36, 25.62, 26.96, 27.25, 27.42,
29.98, 32.54, 32.98, 34.88, 35.34, 35.44, 35.57, 36.29,
37.03, 38.13, 41.88, 44.16, 48.89, 49.78, 51.63, 52.27)
#teste-t
out <-t.test(x=dados,mu=30,alternative="two.sided"
,conf.level=0.95); out
```

```{r}
out$p.value
```

Ao definirmos o nível de significância como α = 0.05 e obtermos um
p-valor de 0.9576505, que é maior que α, podemos concluir que aceitamos
a hipótese nula. Portanto, com um nível de confiança de 95%, temos
evidências que suportam a afirmação de que µ = 30.

Além disso, para reforçar nossa decisão, iremos analisar o intervalo de
confiança de 95% para µ, que também é fornecido pela função
anteriormente utilizada.

```{r}
out$conf.int
```

Assim, podemos determinar que o Intervalo de Confiança (IC) para a
média, com nível de confiança de 95%, é dado por [25.41819, 34.34743], o
qual inclui o valor de µ = 30. Além disso, iremos realizar um teste de
hipótese para a variância utilizando um teste qui-quadrado.

As hipóteses a serem testadas são:

$$
\begin{align*}
H_0 &: \sigma^2 = 95 \\
H_1 &: \sigma^2 \neq 95 \\
\end{align*}
$$

```{r echo=TRUE, message=FALSE, warning=FALSE}
require(EnvStats)
library("EnvStats")
```

```{r}
out2 <- varTest(dados,alternative="two.sided",sigma.squared=95,conf.level=0.95,
data.name="dados"); out2
```

```{r}
out2$p.value
```

O valor p obtido é igual a 0.03321902, enquanto o nível de significância
α é de 0.05. Com base nesses resultados, observamos que o valor p é
menor do que α, indicando evidências para rejeitar a hipótese nula de
que σ² = 95. Além disso, o intervalo de confiança para σ², com nível de
confiança de 0.95, é dado por [98.55821, 271.03709], o qual 95 não está
incluso.

## Questão 5

### 1-

$$
S Q T=\sum_{i=1}^I \sum_{j=1}^{n_i}\left(y_{i j}-\bar{y}\right)^2
$$ Vamos adicionar o termo $-\bar{y}_i+\bar{y}_i$, que é igual a zero:
$$
S Q T=\sum_{i=1}^I \sum_{j=1}^{n_i}\left(\left(y_{i j}-\bar{y}_i\right)+\left(\overline{y_i}-\bar{y}\right)\right)^2=\sum_{i=1}^I \sum_{j=1}^{n_i}\left(y_{i j}-\overline{y_i}\right)^2+2 \sum_{i=1}^I \sum_{j=1}^{n_i}\left(y_{i j}-\overline{y_i}\right)\left(\overline{y_i}-\bar{y}\right)+\sum_{i=1}^I \sum_{j=1}^{n_i}\left(\bar{y}_i-\bar{y}\right)^2
$$

Sabemos que:

$S Q D=\sum_{i=1}^I \sum_{j=1}^{n_i}\left(y_{i j}-\bar{y}_i\right)^2, S Q E=\sum_{i=1}^I \sum_{j=1}^{n_i}\left(\overline{y_i}-\bar{y}\right)^2$.

Também, podemos provar que:

$2 \sum_{i=1}^I \sum_{j=1}^{n_i}\left(y_{i j}-\bar{y}_i\right)\left(\bar{y}_i-\bar{y}\right)=0$

portanto: $$
\sum_{i=1}^I \sum_{j=1}^{n_i}\left(\bar{y}_i-\bar{y}\right)=\sum_{i=1}^I \sum_{j=1}^{n_i} \overline{y_i}-\sum_{i=1}^I \sum_{j=1}^{n_i}=n \bar{y}-n \bar{y}=0
$$ Logo, concluímos que: $$
S Q T=S Q E+S Q D
$$

### 2-

Onde $I$ é o número de níveis e $n$ o tamanho da amostra. $\mathrm{O}$
teste-F é utilizado para indicar se há diferença relevante entre as
médias dos diferentes níveis. Para aceitar ou rejeitar a hipótese nula
de que as médias são iguais, usamos a estatística $F$, calculada como
$F=\frac{Q M E}{Q M D}$. O valor de $F$ será comparado com o valor
crítico da tabela da distribuição $F$ com graus de liberdade
$(I-1, n-I)$. Se o valor observado de $F$ for maior que o valor crítico,
rejeitamos a hipótese nula a um nível de significância $\alpha$.

| Fontes de variação | Graus de liberdade | Soma dos quadrados |      Quadrado médio       |
|:----------------:|:----------------:|:----------------:|:----------------:|
|       Entre        |       $I-1$        |        SQE         | $Q M E=\frac{S Q E}{I-1}$ |
|       Dentro       |       $n-I$        |        SQD         | $Q M D=\frac{S Q D}{n-I}$ |
|       Total        |       $n-1$        |        SQT         | $Q M T=\frac{S Q T}{n-1}$ |

### 3-

Podemos interpretar a estatística F como a razão entre a variabilidade
entre os grupos e a variabilidade dentro dos grupos. Dessa forma, um
valor alto indica que a variabilidade das médias entre os grupos é
significativamente maior do que a variabilidade dentro dos grupos, o que
sugere diferenças nas médias dos grupos. Portanto, para rejeitar a
hipótese nula de igualdade das médias dos grupos, é necessário obter um
valor alto para a estatística F.

## Questão 6)

### 1-

Iremos montar um data frame com os dados do experimênto da questão 6

```{r}
# criação do data frame
x   <- c(7,8,15,11,9,10,12,17,13,18,19,15,14,18,19,17,16,18,19,25,22,23,18,20)     
xf  <- factor(c(5,5,5,5,5,5,10,10,10,10,10,10,15,15,15,15,15,15,20,20,20,20,20,20)) 
df0 <- data.frame(x,xf) # data frame que representa os dados do experimênto da questão
                        # X é a tensão da madeira, variável aleatória de interesse
                        # xf é a concentração de madeira de lei na polpa, o fator
head(df0)
```

Agora, criaremos um novo data frame em função dos níveis da porcentagem de concentração

```{r}
# níveis encontrados no fator
xfl <- levels(df0$xf);xfl
```

```{r}
# organizando os dados em listas em função dos níveis(para auxiliar na análise)
xfl1 <- df0[which(df0$xf=="5"),1]  # 05% de concentração de madeira de lei na polpa
xfl2 <- df0[which(df0$xf=="10"),1] # 10% de concentração de madeira de lei na polpa
xfl3 <- df0[which(df0$xf=="15"),1] # 15% de concentração de madeira de lei na polpa
xfl4 <- df0[which(df0$xf=="20"),1] # 20% de concentração de madeira de lei na polpa
df1  = list(pcnt_5=xfl1,pcnt_10=xfl2,pcnt_15=xfl3,pcnt_20=xfl4)

df1
```

Para a análise descritiva, iremos criar um novo data frame, agora em função dos níveis, junto às medidas de tamanho, média, variância, desvio-padrão para cada fator

```{r}
aux1              <- aggregate(df0$x,by=list(df0$xf),FUN=length)
aux2              <- aggregate(df0$x,by=list(df0$xf),FUN=mean)
aux3              <- aggregate(df0$x,by=list(df0$xf),FUN=var)
aux4              <- aggregate(df0$x,by=list(df0$xf),FUN=sd)
tab.resumo        <- cbind(aux1,aux2$x,aux3$x,aux4$x)
names(tab.resumo) <- c("Fator","Tamanho","Media","Variancia","Desvio-Padrao")

tab.resumo
```

Boxplot para auxiliar na visualização:

```{r}
boxplot(df0$x~df0$xf,xlab="tempo de resistencia", ylab="concentração de madeira na polpa")
```
Por uma análise gráfica, percebemos que o nível de concentração de 15% aparenta ter um variância bem menor que os outros.

### 2-

Agora, realizaremos uma ANOVA:

```{r}
modelo <- aov(x~xf,data=df0) # definição do modelo
names(modelo)
```
### 3- 
estimação dos parâmetros:
```{r}
cf <- coefficients(modelo)
names(cf) <- c("5% de concentração de madeira na polpa", "10% de concentração de madeira na polpa", "15% de concentração de madeira na polpa", "20% de concentração de madeira na polpa");data.frame(cf)



```

De acrodo com os teste ANOVA, podemos assumir que existe diferença significativa entre a tensão da madeira entre os 4 níveis de concentração de madeira na polpa.

### 4- 
Tabela anova e teste-F:
```{r}
options(scipen=999)
smod <- summary(modelo);smod
```
Como o P-Valor é 0.00000359,ou seja, muito menor que 0.05, rejeitamos a hipótese nula, que era de que as médias dos níveis são iguais


### 5-
Em seguida, realizaremos o teste de bartlett para homocedasticidade:

```{r}
bartlett.test(x~xf,data=df0)
```
O p-valor foi maior que 0,05, então não rejeitamos a hipótese nula. Logo, apresentaremos estimativas intervalares para elas, além de realizar um procedimênto de comparações múltiplas para determinar quais diferenças entre médias são significativas.

### 6-  
Estimação intervalar

```{r}
# Numero de niveis de tamanhos amostrais dos fatores 

I <- length(levels(df0$xf))       # número de niveis do fator
n1 <- length(which(df0$xf=="05")) # tamanho da amostra da populacao 1
n2 <- length(which(df0$xf=="10")) # tamanho da amostra da populacao 2
n3 <- length(which(df0$xf=="15")) # tamanho da amostra da populacao 3
n4 <- length(which(df0$xf=="20")) # tamanho da amostra da populacao 4
n5 <- length(which(df0$xf=="25")) # tamanho da amostra da populacao 5
n <- n1+n2+n3+n4+n5               # tamanho da amostral total

#Estimativa intervalar para as médias

ic.mu1 <- confint(modelo)[1,]
ic.mu2 <- confint(modelo)[1,]+as.numeric(coefficients(modelo)[2])
ic.mu3 <- confint(modelo)[1,]+as.numeric(coefficients(modelo)[3])
ic.mu4 <- confint(modelo)[1,]+as.numeric(coefficients(modelo)[4])
ic.mu1 # estimação para 05% de concentração 
ic.mu2 # estimação para 10% de concentração 
ic.mu3 # estimação para 15% de concentração 
ic.mu4 # estimação para 20% de concentração 

```

### 7-  
Agora, utilizaremos o método de Tukey para realizar comparações múltiplas entre as médias dos diferentes níveis do fator

```{r}
tukey <- TukeyHSD(modelo);tukey
plot(tukey,las=2)
```

Pelo resultado do método de Tukey, podemos afirmar que que apenas no intervalo de 10% de concetração a 15% de concentração não existe diferença estatísticamente significativa entre as médias

### 8- 
```{r}
y <- df0[["x"]]
tss <- sum((y - mean(y))^2)
rss <- deviance(modelo) # soma de quadrados residual
sigma2hat <- rss/df.residual(modelo)
sigmahat <- sqrt(sigma2hat)
sigma2hat
```
```{r}
sigmahat
```
```{r}
R2 <- 1-(rss/tss);R2 # coeficiente de explicacao do modelo
```
O coeficiente de determinação é uma medida que indica a qualidade do ajuste de um modelo, variando de 0 a 1. Quanto mais próximo de 1, melhor o modelo se ajusta aos dados. Neste caso específico, o coeficiente de determinação é igual a 0.7462432, indicando um bom ajuste do modelo aos dados.

### 9-

Agroa, apresentaremos uma Análise residual residual para verificar a adequação do modelo proposto
```{r}
r_squared <- smod[[1]]$`Pr(>F)`[1] # coeficiente de explicação 
sq.residual <- sum(residuals(modelo)^(2))
sigma.hat2 <- sq.residual/df.residual(modelo)
sigma.hat <- sqrt(sigma.hat2)
par(mfrow=c(2,2))
boxplot(modelo$residuals~modelo$model[,2],xlab="concentração de madeira na polpa",ylab=expression(r),
        names=c("05","10","15","20"),col=c("tan","tan1","tan2","tan3"))
plot(modelo$residuals~modelo$fitted.values,xlab="Valores ajustados",ylab=expression(r))
qqnorm(modelo$residuals/sigma.hat,xlab="Quantis teoricos",ylab=expression(u==r/hat(sigma)),main="")
qqline(modelo$residuals/sigma.hat,col="red")
plot(modelo$fitted.values,sqrt(abs(modelo$residuals/sigma.hat)),
xlab="Valores ajustados",ylab=expression(sqrt(abs(u))))
```
### 10-
```{r}
predict(modelo)
```
As predições de resistência da medeira, para cada uma das concentrações, são: Concentração 5%: 10, Concentração 10%: 15.66667, Concentração
15%: 17, Concentração 20%: 21.16667

### questão 7)
```{r}
modelo.kw <- kruskal.test(x~xf,data=df0)
print(modelo.kw)
```
Devido ao fato de o valor de p ser menor que o nível de significância, 0.05, podemos rejeitar a hipótese de igualdade entre as médias dos diferentes níveis. Essa conclusão está em conformidade com o resultado do teste realizado na questão anterior.








